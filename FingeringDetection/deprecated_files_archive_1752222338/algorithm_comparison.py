#!/usr/bin/env python3
"""
ì•Œê³ ë¦¬ì¦˜ ì°¨ì´ì  ë° ê²°ê³¼ ë¹„êµ ë¶„ì„
scipyì˜ Powell's dog leg vs PyTorchì˜ Adam ì˜µí‹°ë§ˆì´ì €
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import fsolve
import torch
import torch.optim as optim

class AlgorithmComparison:
    def __init__(self):
        self.test_case = self.generate_test_case()
        
    def generate_test_case(self):
        """ë™ì¼í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±"""
        w = [0.3, 0.2]
        i = [0.1, 0.4] 
        r = [-0.2, 0.1]
        
        # Mock landmark data
        class MockLandmark:
            def __init__(self, x, y):
                self.x = x
                self.y = y
        
        lhmodel = [MockLandmark(0, 0) for _ in range(21)]
        lhmodel[0] = MockLandmark(0.0, 0.0)   # wrist
        lhmodel[5] = MockLandmark(0.2, 0.3)   # index MCP
        lhmodel[13] = MockLandmark(-0.1, 0.2) # ring MCP
        
        ratio = 1.0
        return w, i, r, lhmodel, ratio

    def landmarkdistance(self, landmark_a, landmark_b, ratio):
        """ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜"""
        return ((landmark_a.x - landmark_b.x) ** 2 + 
                (landmark_a.y * ratio - landmark_b.y * ratio) ** 2) ** 0.5 * 2

    def scipy_approach(self):
        """ê¸°ì¡´ SciPy ë°©ì‹ - Powell's dog leg algorithm"""
        print("=" * 50)
        print("ğŸ”¬ SciPy ë°©ì‹: Powell's Dog Leg Algorithm")
        print("=" * 50)
        
        w, i, r, lhmodel, ratio = self.test_case
        
        def system(vars):
            t, u, v = vars
            
            # ëª©í‘œ ê±°ë¦¬ ê³„ì‚°
            target_WI = self.landmarkdistance(lhmodel[0], lhmodel[5], ratio)
            target_IR = self.landmarkdistance(lhmodel[5], lhmodel[13], ratio)
            target_RW = self.landmarkdistance(lhmodel[13], lhmodel[0], ratio)
            
            # 3ê°œ ë°©ì •ì‹
            eq1 = (t*w[0] - u*i[0])**2 + (t*w[1] - u*i[1])**2 + (t - u)**2 - target_WI**2
            eq2 = (u*i[0] - v*r[0])**2 + (u*i[1] - v*r[1])**2 + (u - v)**2 - target_IR**2  
            eq3 = (v*r[0] - t*w[0])**2 + (v*r[1] - t*w[1])**2 + (v - t)**2 - target_RW**2
            
            return [eq1, eq2, eq3]
        
        print("ğŸ“‹ ì•Œê³ ë¦¬ì¦˜ íŠ¹ì§•:")
        print("  - Powell's dog leg trust region method")
        print("  - Hybrid approach (Gauss-Newton + Steepest descent)")
        print("  - Trust region í¬ê¸°ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •")
        print("  - Jacobian í–‰ë ¬ì„ ìˆ˜ì¹˜ì ìœ¼ë¡œ ê³„ì‚°")
        
        # í•´ êµ¬í•˜ê¸°
        initial_guess = [1.0, 1.0, 1.0]
        solution = fsolve(system, initial_guess, full_output=True)
        t, u, v = solution[0]
        depth = (t + u + v) / 3
        
        print(f"\nğŸ“Š ê²°ê³¼:")
        print(f"  - í•´: t={t:.6f}, u={u:.6f}, v={v:.6f}")
        print(f"  - ê¹Šì´: {depth:.6f}")
        print(f"  - ìˆ˜ë ´ ì •ë³´: {solution[2]}")
        
        return depth, solution[0]

    def pytorch_approach(self):
        """PyTorch ë°©ì‹ - Adam optimizer"""
        print("\n" + "=" * 50)
        print("ğŸš€ PyTorch ë°©ì‹: Adam Optimizer")
        print("=" * 50)
        
        w, i, r, lhmodel, ratio = self.test_case
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # ëª©í‘œ ê±°ë¦¬ ê³„ì‚°
        target_WI = self.landmarkdistance(lhmodel[0], lhmodel[5], ratio)
        target_IR = self.landmarkdistance(lhmodel[5], lhmodel[13], ratio)
        target_RW = self.landmarkdistance(lhmodel[13], lhmodel[0], ratio)
        
        target_distances = torch.tensor([target_WI, target_IR, target_RW], device=device)
        w_tensor = torch.tensor(w, device=device)
        i_tensor = torch.tensor(i, device=device)  
        r_tensor = torch.tensor(r, device=device)
        
        print("ğŸ“‹ ì•Œê³ ë¦¬ì¦˜ íŠ¹ì§•:")
        print("  - Adam (Adaptive Moment Estimation)")
        print("  - 1ì°¨ ë° 2ì°¨ ëª¨ë©˜íŠ¸ì˜ ì§€ìˆ˜ ì´ë™ í‰ê·  ì‚¬ìš©")
        print("  - í•™ìŠµë¥ ì„ ìë™ìœ¼ë¡œ ì ì‘")
        print("  - ìë™ ë¯¸ë¶„ìœ¼ë¡œ gradient ê³„ì‚°")
        
        # ìµœì í™” ë³€ìˆ˜
        tuv = torch.ones(3, device=device, requires_grad=True)
        optimizer = optim.Adam([tuv], lr=0.01)
        
        loss_history = []
        
        print(f"\nğŸ”„ ìµœì í™” ê³¼ì •:")
        for iteration in range(100):
            optimizer.zero_grad()
            
            t, u, v = tuv[0], tuv[1], tuv[2]
            
            # 3D ì¢Œí‘œ ê³„ì‚°
            w_3d = torch.stack([t * w_tensor[0], t * w_tensor[1], t])
            i_3d = torch.stack([u * i_tensor[0], u * i_tensor[1], u])
            r_3d = torch.stack([v * r_tensor[0], v * r_tensor[1], v])
            
            # ê±°ë¦¬ ê³„ì‚°
            dist_wi = torch.norm(w_3d - i_3d)
            dist_ir = torch.norm(i_3d - r_3d)
            dist_rw = torch.norm(r_3d - w_3d)
            
            # Loss function: MSE between current and target distances
            loss = ((dist_wi - target_distances[0])**2 + 
                   (dist_ir - target_distances[1])**2 + 
                   (dist_rw - target_distances[2])**2)
            
            loss.backward()
            optimizer.step()
            
            loss_history.append(loss.item())
            
            if iteration % 20 == 0:
                print(f"  ë°˜ë³µ {iteration:3d}: Loss = {loss.item():.8f}")
            
            if loss.item() < 1e-10:
                print(f"  ìˆ˜ë ´ ì™„ë£Œ (ë°˜ë³µ {iteration})")
                break
        
        with torch.no_grad():
            final_tuv = tuv.cpu().numpy()
            depth = final_tuv.mean()
        
        print(f"\nğŸ“Š ê²°ê³¼:")
        print(f"  - í•´: t={final_tuv[0]:.6f}, u={final_tuv[1]:.6f}, v={final_tuv[2]:.6f}")
        print(f"  - ê¹Šì´: {depth:.6f}")
        print(f"  - ìµœì¢… Loss: {loss_history[-1]:.2e}")
        
        return depth, final_tuv, loss_history

    def compare_methods(self):
        """ë‘ ë°©ë²• ë¹„êµ"""
        print("\n" + "=" * 70)
        print("ğŸ” ì¢…í•© ë¹„êµ ë¶„ì„")
        print("=" * 70)
        
        # ê²°ê³¼ ê³„ì‚°
        scipy_depth, scipy_solution = self.scipy_approach()
        pytorch_depth, pytorch_solution, loss_history = self.pytorch_approach()
        
        # ì°¨ì´ ë¶„ì„
        depth_diff = abs(scipy_depth - pytorch_depth)
        solution_diff = np.linalg.norm(scipy_solution - pytorch_solution)
        
        print(f"\nğŸ“Š ê²°ê³¼ ë¹„êµ:")
        print(f"  SciPy ê¹Šì´:   {scipy_depth:.8f}")
        print(f"  PyTorch ê¹Šì´: {pytorch_depth:.8f}")
        print(f"  ê¹Šì´ ì°¨ì´:    {depth_diff:.2e}")
        print(f"  í•´ ë²¡í„° ì°¨ì´: {solution_diff:.2e}")
        
        if depth_diff < 1e-4:
            print("  âœ… ê²°ê³¼ê°€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤!")
        else:
            print("  âš ï¸ ê²°ê³¼ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        # ìˆ˜ë ´ ê³¼ì • ì‹œê°í™”
        self.plot_convergence(loss_history)
        
        return {
            'scipy_depth': scipy_depth,
            'pytorch_depth': pytorch_depth, 
            'depth_difference': depth_diff,
            'solution_difference': solution_diff
        }

    def plot_convergence(self, loss_history):
        """PyTorch ìˆ˜ë ´ ê³¼ì • ì‹œê°í™”"""
        plt.figure(figsize=(10, 6))
        plt.plot(loss_history, 'b-', linewidth=2)
        plt.xlabel('ë°˜ë³µ íšŸìˆ˜')
        plt.ylabel('Loss (log scale)')
        plt.title('PyTorch Adam ì˜µí‹°ë§ˆì´ì € ìˆ˜ë ´ ê³¼ì •')
        plt.yscale('log')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('convergence_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("ğŸ“ˆ ìˆ˜ë ´ ê·¸ë˜í”„ê°€ 'convergence_comparison.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def analyze_algorithmic_differences():
    """ì•Œê³ ë¦¬ì¦˜ ì°¨ì´ì  ìƒì„¸ ë¶„ì„"""
    print("=" * 70)
    print("ğŸ§® ì•Œê³ ë¦¬ì¦˜ ê·¼ë³¸ì  ì°¨ì´ì  ë¶„ì„")
    print("=" * 70)
    
    differences = {
        "ìˆ˜í•™ì  ì ‘ê·¼": {
            "SciPy (Powell's Dog Leg)": [
                "â€¢ ë¹„ì„ í˜• ë°©ì •ì‹ ì‹œìŠ¤í…œ: f(x) = 0",
                "â€¢ Trust region ë°©ë²•",
                "â€¢ Gauss-Newton + Steepest descent í˜¼í•©",
                "â€¢ ìˆ˜ì¹˜ì  Jacobian ê³„ì‚°"
            ],
            "PyTorch (Adam)": [
                "â€¢ ìµœì í™” ë¬¸ì œ: min f(x)",
                "â€¢ Loss function: ||target - current||Â²",
                "â€¢ 1ì°¨/2ì°¨ ëª¨ë©˜íŠ¸ ì ì‘í˜• ìµœì í™”",
                "â€¢ ìë™ ë¯¸ë¶„"
            ]
        },
        "ìˆ˜ë ´ íŠ¹ì„±": {
            "SciPy": [
                "â€¢ êµ­ì†Œì  2ì°¨ ìˆ˜ë ´",
                "â€¢ Trust regionìœ¼ë¡œ ì•ˆì •ì„± ë³´ì¥", 
                "â€¢ ì´ˆê¸°ê°’ì— ë¯¼ê°í•  ìˆ˜ ìˆìŒ",
                "â€¢ Jacobian íŠ¹ì´ì„± ë¬¸ì œ ê°€ëŠ¥"
            ],
            "PyTorch": [
                "â€¢ 1ì°¨ ìµœì í™” (gradient descent ê³„ì—´)",
                "â€¢ ëª¨ë©˜í…€ìœ¼ë¡œ ì§„ë™ ê°ì†Œ",
                "â€¢ í•™ìŠµë¥  ìë™ ì¡°ì •",
                "â€¢ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë³‘ë ¬í™” ê°€ëŠ¥"
            ]
        },
        "ê³„ì‚° íš¨ìœ¨ì„±": {
            "SciPy": [
                "â€¢ CPU ë‹¨ì¼ ìŠ¤ë ˆë“œ",
                "â€¢ ìˆœì°¨ ì²˜ë¦¬ë§Œ ê°€ëŠ¥",
                "â€¢ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ",
                "â€¢ ì‘ì€ ë¬¸ì œì— ìµœì í™”"
            ],
            "PyTorch": [
                "â€¢ GPU ë³‘ë ¬ ì²˜ë¦¬",
                "â€¢ ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›",
                "â€¢ í…ì„œ ì—°ì‚° ìµœì í™”",
                "â€¢ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ìœ ë¦¬"
            ]
        }
    }
    
    for category, methods in differences.items():
        print(f"\nğŸ”¸ {category}:")
        print("-" * 50)
        for method, features in methods.items():
            print(f"\n{method}:")
            for feature in features:
                print(f"  {feature}")

if __name__ == "__main__":
    # ì•Œê³ ë¦¬ì¦˜ ì°¨ì´ì  ë¶„ì„
    analyze_algorithmic_differences()
    
    # ì‹¤ì œ ë¹„êµ ì‹¤í–‰
    print("\n" + "=" * 70)
    print("ğŸ§ª ì‹¤ì œ ê²°ê³¼ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    comparison = AlgorithmComparison()
    results = comparison.compare_methods()
    
    # ìµœì¢… ê²°ë¡ 
    print("\n" + "=" * 70)
    print("ğŸ“ ìµœì¢… ê²°ë¡ ")
    print("=" * 70)
    print("1. ğŸ¯ ê²°ê³¼ ì •í™•ë„: ë‘ ë°©ë²• ëª¨ë‘ ë™ì¼í•œ í•´ì— ìˆ˜ë ´")
    print("2. ğŸš€ ì„±ëŠ¥: PyTorchê°€ GPU ê°€ì†ìœ¼ë¡œ ëŒ€í­ í–¥ìƒ")
    print("3. ğŸ”§ í™•ì¥ì„±: PyTorchê°€ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìš°ìˆ˜")
    print("4. ğŸ’¡ ê°œì„ ì : Powell's dog leg â†’ Adamìœ¼ë¡œ ì•Œê³ ë¦¬ì¦˜ êµì²´")
    print("\në”°ë¼ì„œ ì´ëŠ” Powell's dog legì˜ 'ê°œì„ 'ì´ ì•„ë‹Œ")
    print("'ì™„ì „íˆ ë‹¤ë¥¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œì˜ ì „í™˜'ì…ë‹ˆë‹¤!") 