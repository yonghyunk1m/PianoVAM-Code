#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MIDI ê¸°ë°˜ Floating Detection í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ ë°©ì‹ê³¼ ìƒˆë¡œìš´ MIDI ê¸°ë°˜ ë°©ì‹ì„ ë¹„êµ
JSON ë°ì´í„° í˜•ì‹ ì§€ì›
"""

import sys
import os
import pickle
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append('.')
from midi_based_floating_detector import MIDIBasedFloatingDetector, detect_floating_with_midi_integration


@dataclass
class HandLandmark:
    """ì† ëœë“œë§ˆí¬ í¬ì¸íŠ¸"""
    x: float
    y: float


@dataclass
class HandData:
    """ì† ë°ì´í„° í´ë˜ìŠ¤ (ê¸°ì¡´ handclassì™€ í˜¸í™˜)"""
    handtype: str
    handlandmark: List[HandLandmark]
    handframe: int
    handdepth: float = 1.0


def load_test_data(target_video: str = None):
    """Cache ë””ë ‰í† ë¦¬ì˜ handlist pickle íŒŒì¼ ë¡œë“œ"""
    print("ğŸ” Cache handlist ë°ì´í„° ê²€ìƒ‰ ì¤‘...")
    
    cache_dir = Path("cache")
    if not cache_dir.exists():
        print("âŒ cache ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ handlist íŒŒì¼ë“¤ ì°¾ê¸°
    handlist_files = []
    for item in cache_dir.iterdir():
        if item.is_dir():
            potential_handlist = list(item.glob("handlist_*.pkl"))
            if potential_handlist:
                handlist_files.extend(potential_handlist)
    
    if not handlist_files:
        print("âŒ handlist pickle íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
    
    # íŠ¹ì • ë¹„ë””ì˜¤ ì§€ì • ë˜ëŠ” ì²« ë²ˆì§¸ ë°ì´í„° ì‚¬ìš©
    if target_video:
        target_file = next((f for f in handlist_files if target_video in f.stem), None)
        if not target_file:
            print(f"âŒ ì§€ì •ëœ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_video}")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ë“¤: {[f.stem for f in handlist_files]}")
            return None, None, None
    else:
        # í¬ê¸°ê°€ ì ë‹¹í•œ íŒŒì¼ ì„ íƒ (í…ŒìŠ¤íŠ¸ ìš©ì´ì„±ì„ ìœ„í•´) - limit600ì´ ì¢‹ì„ ê²ƒ ê°™ìŒ
        suitable_files = [f for f in handlist_files if "limit600" in f.stem or "limit1200" in f.stem]
        if suitable_files:
            target_file = suitable_files[0]
        else:
            target_file = handlist_files[0]
    
    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {target_file.stem}")
    print(f"   íŒŒì¼ í¬ê¸°: {target_file.stat().st_size / 1024 / 1024:.1f}MB")
    
    # handlist ë¡œë“œ
    with open(target_file, 'rb') as f:
        handlist = pickle.load(f)
    
    # ë¹„ë””ì˜¤ ì´ë¦„ ì¶”ì¶œ 
    video_name = target_file.stem.replace('handlist_', '').replace('_limit600', '').replace('_limit1200', '').replace('_limit6000', '')
    
    # ë¹„ë””ì˜¤ ì •ë³´ (ê°„ë‹¨í•œ ë¹„ìœ¨ ê³„ì‚°)
    ratio = 9/16  # ê¸°ë³¸ ë¹„ìœ¨
    
    print(f"   handlist: {len(handlist)}í”„ë ˆì„")
    total_hands = sum(len(hands) for hands in handlist if hands)
    print(f"   ì´ ì† ë°ì´í„°: {total_hands:,}ê°œ")
    
    return handlist, video_name, ratio



def run_comparison_test(handlist, video_name, ratio):
    """ê¸°ì¡´ ë°©ì‹ê³¼ MIDI ê¸°ë°˜ ë°©ì‹ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”„ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ Floating Detection ì‹¤í–‰")
    print("=" * 60)
    
    # 1. ìƒˆë¡œìš´ MIDI ê¸°ë°˜ ë°©ì‹
    print("\n1ï¸âƒ£ MIDI ê¸°ë°˜ Floating Detection")
    print("-" * 40)
    
    midi_detector = MIDIBasedFloatingDetector()
    midi_results = midi_detector.detect_floating_hands_with_midi(handlist, video_name, ratio)
    
    # 2. ê¸°ì¡´ ê¹Šì´ ê¸°ë°˜ ë°©ì‹ (ê°„ë‹¨ ë²„ì „)
    print("\n2ï¸âƒ£ ê¸°ì¡´ ê¹Šì´ ê¸°ë°˜ Detection")
    print("-" * 40)
    
    original_results = []
    for hands in handlist:
        if not hands:
            continue
        for hand in hands:
            # ê°„ë‹¨í•œ ê¹Šì´ ê³„ì‚°
            depth_value = midi_detector._calculate_simple_depth(hand)
            floating_status = 'floating' if depth_value < 0.9 else 'notfloating'
            
            original_results.append([
                hand.handframe,
                hand.handtype,
                depth_value,
                floating_status
            ])
    
    print(f"   ğŸ” ê¸°ì¡´ ë°©ì‹ ì™„ë£Œ: {len(original_results)}ê°œ ë¶„ì„")
    
    return midi_results, original_results


def analyze_differences(midi_results, original_results, video_name):
    """ë‘ ë°©ì‹ì˜ ì°¨ì´ì  ë¶„ì„"""
    print("\nğŸ“Š ê²°ê³¼ ë¹„êµ ë¶„ì„")
    print("=" * 60)
    
    # DataFrame ë³€í™˜
    midi_df = pd.DataFrame(midi_results, columns=['frame', 'hand_type', 'depth', 'floating_status'])
    original_df = pd.DataFrame(original_results, columns=['frame', 'hand_type', 'depth', 'floating_status'])
    
    # ê¸°ë³¸ í†µê³„
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„:")
    print(f"   ì´ ì† ë°ì´í„°: {len(midi_df)}ê°œ")
    
    # Floating ë¹„ìœ¨ ë¹„êµ
    midi_floating_rate = (midi_df['floating_status'] == 'floating').mean() * 100
    original_floating_rate = (original_df['floating_status'] == 'floating').mean() * 100
    
    print(f"\nğŸ¯ Floating ë¹„ìœ¨ ë¹„êµ:")
    print(f"   MIDI ê¸°ë°˜:    {midi_floating_rate:.1f}%")
    print(f"   ê¸°ì¡´ ë°©ì‹:    {original_floating_rate:.1f}%")
    print(f"   ì°¨ì´:        {midi_floating_rate - original_floating_rate:+.1f}%")
    
    # ì†ë³„ ë¶„ì„
    print(f"\nğŸ‘ ì†ë³„ ë¶„ì„:")
    for hand_type in ['Left', 'Right']:
        midi_hand = midi_df[midi_df['hand_type'] == hand_type]
        original_hand = original_df[original_df['hand_type'] == hand_type]
        
        if len(midi_hand) > 0:
            midi_rate = (midi_hand['floating_status'] == 'floating').mean() * 100
            original_rate = (original_hand['floating_status'] == 'floating').mean() * 100
            
            print(f"   {hand_type}ì†:")
            print(f"     MIDI ê¸°ë°˜: {midi_rate:.1f}%")
            print(f"     ê¸°ì¡´ ë°©ì‹: {original_rate:.1f}%")
            print(f"     ì°¨ì´: {midi_rate - original_rate:+.1f}%")
    
    # í”„ë ˆì„ë³„ ì¼ì¹˜ë„ ë¶„ì„
    print(f"\nğŸ” íŒì • ë³€í™” ë¶„ì„:")
    
    # ê°™ì€ í”„ë ˆì„-ì† ì¡°í•©ìœ¼ë¡œ ë³‘í•©
    merged = midi_df.merge(original_df, on=['frame', 'hand_type'], suffixes=('_midi', '_original'))
    
    # íŒì •ì´ ë‹¤ë¥¸ ê²½ìš°ë“¤
    different_judgments = merged[merged['floating_status_midi'] != merged['floating_status_original']]
    
    if len(different_judgments) > 0:
        print(f"   íŒì • ì°¨ì´: {len(different_judgments)}ê°œ ({len(different_judgments)/len(merged)*100:.1f}%)")
        
        # ë³€í™” íŒ¨í„´ ë¶„ì„
        midi_to_playing = different_judgments[
            (different_judgments['floating_status_midi'] == 'notfloating') & 
            (different_judgments['floating_status_original'] == 'floating')
        ]
        
        playing_to_midi = different_judgments[
            (different_judgments['floating_status_midi'] == 'floating') & 
            (different_judgments['floating_status_original'] == 'notfloating')
        ]
        
        print(f"   Floating â†’ Playing: {len(midi_to_playing)}ê°œ (MIDI ì •ë³´ë¡œ ì—°ì£¼ ì¤‘ íŒì •)")
        print(f"   Playing â†’ Floating: {len(playing_to_midi)}ê°œ (MIDI ì •ë³´ë¡œ ì¡°ìš©í•œ ìˆœê°„ íŒì •)")
    else:
        print(f"   ëª¨ë“  íŒì •ì´ ì¼ì¹˜í•©ë‹ˆë‹¤!")
    
    return merged


def visualize_timeline_comparison(merged_df, video_name, max_samples=2000):
    """íƒ€ì„ë¼ì¸ ì‹œê°í™”"""
    print(f"\nğŸ“Š íƒ€ì„ë¼ì¸ ì‹œê°í™” ìƒì„±...")
    
    # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ê·¸ë˜í”„ê°€ ë³µì¡í•´ì§)
    if len(merged_df) > max_samples:
        sample_df = merged_df.sample(n=max_samples).sort_values('frame')
    else:
        sample_df = merged_df.sort_values('frame')
    
    # ì‹œê°„ ì¶• ìƒì„± (í”„ë ˆì„ â†’ ì´ˆ)
    sample_df['time'] = sample_df['frame'] / 20  # 20fps ê°€ì •
    
    fig, axes = plt.subplots(2, 1, figsize=(15, 10))
    
    # ì¢Œì†ê³¼ ìš°ì†ë³„ë¡œ ì‹œê°í™”
    for idx, hand_type in enumerate(['Left', 'Right']):
        ax = axes[idx]
        
        hand_data = sample_df[sample_df['hand_type'] == hand_type]
        if len(hand_data) == 0:
            continue
        
        # MIDI ê¸°ë°˜ ê²°ê³¼
        midi_floating = hand_data[hand_data['floating_status_midi'] == 'floating']['time']
        midi_playing = hand_data[hand_data['floating_status_midi'] == 'notfloating']['time']
        
        # ê¸°ì¡´ ë°©ì‹ ê²°ê³¼  
        original_floating = hand_data[hand_data['floating_status_original'] == 'floating']['time']
        original_playing = hand_data[hand_data['floating_status_original'] == 'notfloating']['time']
        
        # ì‹œê°í™”
        ax.scatter(midi_floating, [1] * len(midi_floating), 
                  alpha=0.6, s=2, color='red', label='MIDI: Floating')
        ax.scatter(midi_playing, [1] * len(midi_playing), 
                  alpha=0.6, s=2, color='blue', label='MIDI: Playing')
        
        ax.scatter(original_floating, [0] * len(original_floating), 
                  alpha=0.6, s=2, color='orange', label='ê¸°ì¡´: Floating')
        ax.scatter(original_playing, [0] * len(original_playing), 
                  alpha=0.6, s=2, color='green', label='ê¸°ì¡´: Playing')
        
        ax.set_title(f'{hand_type}ì† Floating Detection ë¹„êµ')
        ax.set_xlabel('ì‹œê°„ (ì´ˆ)')
        ax.set_yticks([0, 1])
        ax.set_yticklabels(['ê¸°ì¡´ ë°©ì‹', 'MIDI ê¸°ë°˜'])
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'floating_comparison_{video_name}.png', dpi=150, bbox_inches='tight')
    
    print(f"   ğŸ’¾ ê·¸ë˜í”„ ì €ì¥: floating_comparison_{video_name}.png")
    
    # ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì£¼ë ¤ê³  í•˜ì§€ë§Œ í™˜ê²½ì—ì„œ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
    try:
        plt.show()
    except:
        print("   â„¹ï¸  GUI í™˜ê²½ì´ ì•„ë‹ˆë¯€ë¡œ ê·¸ë˜í”„ í‘œì‹œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    plt.close()


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸµ MIDI ê¸°ë°˜ Floating Detection í…ŒìŠ¤íŠ¸ (Cache Handlist)")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    handlist, video_name, ratio = load_test_data()
    
    if handlist is None:
        return
    
    # ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    midi_results, original_results = run_comparison_test(handlist, video_name, ratio)
    
    # ê²°ê³¼ ë¶„ì„
    merged_df = analyze_differences(midi_results, original_results, video_name)
    
    # ì‹œê°í™”
    visualize_timeline_comparison(merged_df, video_name)
    
    # ê²°ê³¼ ì €ì¥
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥...")
    with open(f'midi_floating_results_{video_name}.pkl', 'wb') as f:
        pickle.dump(midi_results, f)
    
    with open(f'original_floating_results_{video_name}.pkl', 'wb') as f:
        pickle.dump(original_results, f)
    
    print(f"   âœ… ì €ì¥ ì™„ë£Œ!")
    
    print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"í•µì‹¬ ê°œì„ ì‚¬í•­:")
    print(f"âœ… MIDIê°€ ì—°ì£¼ë˜ëŠ” ìˆœê°„ â†’ ì ˆëŒ€ floating ì•„ë‹˜")
    print(f"âœ… MIDIê°€ ì¡°ìš©í•œ ìˆœê°„ â†’ ê¹Šì´ë¡œ ì •í™•í•œ íŒì •")
    print(f"âœ… ë…¼ë¦¬ì ì´ê³  ì¼ê´€ì„± ìˆëŠ” floating ê°ì§€")


if __name__ == "__main__":
    main() 