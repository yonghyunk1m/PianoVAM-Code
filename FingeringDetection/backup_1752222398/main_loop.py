import cv2
import numpy as np
import os
# STEP 1: Import the necessary modules.
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from floatinghands import *
from midicomparison import *
import pickle
from tqdm.auto import tqdm
from stqdm import stqdm
import time as timemodule
import json
# Note: file order is main>evaluate>midicomparison>floatinghands

# STEP 2: Create an HandLandmarker object with GPU support.
# Get the directory where this script is located
script_dir = os.path.dirname(os.path.abspath(__file__))

def check_gpu_support():
    """GPU ì§€ì› ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        # OpenCV GPU ì§€ì› í™•ì¸
        has_opencv_gpu = cv2.cuda.getCudaEnabledDeviceCount() > 0
        
        # TensorFlow GPU ì§€ì› í™•ì¸ (ì„ íƒì )
        try:
            import tensorflow as tf
            has_tf_gpu = len(tf.config.list_physical_devices('GPU')) > 0
        except ImportError:
            has_tf_gpu = False
        
        print(f"ğŸ” GPU ì§€ì› ìƒíƒœ:")
        print(f"   OpenCV CUDA: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if has_opencv_gpu else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")
        print(f"   TensorFlow GPU: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if has_tf_gpu else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")
        
        if not has_opencv_gpu and not has_tf_gpu:
            print("ğŸ’¡ GPU ê°€ì†ì„ ìœ„í•´ CUDA ë“œë¼ì´ë²„ì™€ OpenCV-CUDA ë˜ëŠ” TensorFlow-GPUë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
            
        return has_opencv_gpu or has_tf_gpu
            
    except Exception as e:
        print(f"âš ï¸ GPU ì§€ì› í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def create_handlandmarker_with_gpu():
    """GPU ì§€ì›ì„ í¬í•¨í•œ HandLandmarker ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    hand_landmarker_path = os.path.join(script_dir, "hand_landmarker.task")
    
    # GPU delegate ì„¤ì • ì‹œë„
    base_options = python.BaseOptions(model_asset_path=hand_landmarker_path)
    
    try:
        # GPU delegate ì‹œë„
        if hasattr(python.BaseOptions, 'Delegate') and hasattr(python.BaseOptions.Delegate, 'GPU'):
            base_options = python.BaseOptions(
                model_asset_path=hand_landmarker_path,
                delegate=python.BaseOptions.Delegate.GPU
            )
            print("ğŸš€ GPU delegate ì„¤ì • ì™„ë£Œ - GPU ê°€ì† í™œì„±í™”")
        else:
            print("âš ï¸ GPU delegate ë¯¸ì§€ì› - CPU ì‚¬ìš©")
    except Exception as e:
        print(f"âš ï¸ GPU delegate ì„¤ì • ì‹¤íŒ¨, CPU ì‚¬ìš©: {e}")
    
    options = vision.HandLandmarkerOptions(
        base_options=base_options,
        running_mode=mp.tasks.vision.RunningMode.VIDEO,
        num_hands=2,
        min_hand_detection_confidence=min_hand_detection_confidence,
        min_hand_presence_confidence=min_hand_presence_confidence,
        min_tracking_confidence=min_tracking_confidence,
    )
    
    return vision.HandLandmarker.create_from_options(options)

# Create paths relative to script location
min_hand_detection_confidence = 0.85
min_hand_presence_confidence = 0.8
min_tracking_confidence = 0.5
VisionRunningMode = mp.tasks.vision.RunningMode

# GPU ì§€ì› í™•ì¸
print("ğŸš€ MediaPipe HandLandmarker ì´ˆê¸°í™”...")
check_gpu_support()

# HandLandmarker ìƒì„± (GPU ì§€ì› í¬í•¨)
detector = create_handlandmarker_with_gpu()
print("âœ… MediaPipe HandLandmarker ì´ˆê¸°í™” ì™„ë£Œ")

filepath = os.path.join(script_dir, 'videocapture') #Video capture directory relative to script

def datagenerate(videoname):
    start = timemodule.time()
    video = cv2.VideoCapture(
        os.path.join(filepath,
                     videoname,
        )
    )
    width = video.get(cv2.CAP_PROP_FRAME_WIDTH)
    height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)

    ratio=height/width
    dirname = os.path.join(
        filepath,
        videoname[:-4]+'_'+f"{min_hand_detection_confidence*100}{min_hand_presence_confidence*100}{min_tracking_confidence*100}",
    )

    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_rate = video.get(cv2.CAP_PROP_FPS)
    with open(
        os.path.join(script_dir, "keyboardcoordinateinfo.pkl"),
        "rb",
    ) as f:
        keyboardcoordinateinfo = pickle.load(f)
    keyboard = generatekeyboard(
        lu=keyboardcoordinateinfo[videoname[:-4]][0],
        ru=keyboardcoordinateinfo[videoname[:-4]][1],
        ld=keyboardcoordinateinfo[videoname[:-4]][2],
        rd=keyboardcoordinateinfo[videoname[:-4]][3],
        blackratio=keyboardcoordinateinfo[videoname[:-4]][4],
        ldistortion=keyboardcoordinateinfo[videoname[:-4]][5],
        rdistortion=keyboardcoordinateinfo[videoname[:-4]][6],
        cdistortion=keyboardcoordinateinfo[videoname[:-4]][7],
    )
    if not os.path.exists(dirname):
        os.makedirs(dirname)

    # ê¸°ì¡´ íŒŒì¼ë“¤ ì •ë¦¬
    for file in os.scandir(dirname):
        os.remove(file.path)

    if not video.isOpened():
        print("Could not Open :", filepath)
        exit(0)

    # ë¹„ë””ì˜¤ì—ì„œ ì§ì ‘ í”„ë ˆì„ì„ ì½ì–´ì„œ MediaPipe ì²˜ë¦¬
    nohandframelist = []
    handlist = []
    handtypelist = []
    
    pbar2 = tqdm(total=frame_count)
    frame = 0
    
    for _ in stqdm(range(frame_count), desc="Generating hand information from video frames..."):
        if frame < frame_count:
            ret, cv_image = video.read()
            if not ret:
                break
                
            # OpenCV ì´ë¯¸ì§€ë¥¼ MediaPipe í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)
            
            time = frame * int(1000 / frame_rate)
            detection_result = detector.detect_for_video(image, timestamp_ms=time)
            
            if len(detection_result.handedness) == 0:
                nohandframelist.append(frame)

            for j in range(len(detection_result.handedness)):
                for finger_landmark in detection_result.hand_landmarks[j]:
                    finger_landmark.x = finger_landmark.x * 2 - 1  # [0,1] -> [-1,1]
                    finger_landmark.y = finger_landmark.y * 2 - 1  # [0,1] -> [-1,1]

            handsinfo = [
                handclass(
                    handtype=detection_result.handedness[j][0].category_name,
                    handlandmark=detection_result.hand_landmarks[j],
                    handframe=frame,
                )
                for j in range(len(detection_result.handedness))
            ]
            handlist.append(handsinfo)
            handtypelist.append([hand.handtype for hand in handsinfo])
            
            # í‚¤ë³´ë“œ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ë””ë²„ê¹… ìš©ë„)
            if frame == max(0, frame_count - 100):
                keyboard_image = draw_keyboard_on_image(image.numpy_view(), keyboard)
                cv2.imwrite(
                    dirname + "/" + "keyboard.jpg", cv2.cvtColor(keyboard_image, cv2.COLOR_BGR2RGB)
                )
            
            pbar2.update(1)
            frame += 1
    
    video.release()

    lhmodel,rhmodel=modelskeleton(handlist)
    depthlist(handlist,lhmodel,rhmodel,ratio)

    faultyframe = faultyframes(handlist)
    pbar2.close()
    print("Calculating faulty frames...")
    floatingframes = detectfloatingframes(handlist, frame_count, faultyframe, lhmodel, rhmodel, ratio=ratio)
    with open(
        dirname
        + "/floatingframes_"
        + videoname[:-4]
        + "_"
        + f"{min_hand_detection_confidence*100}{min_hand_presence_confidence*100}{min_tracking_confidence*100}"
        + ".pkl",
        "wb",
    ) as f:
        pickle.dump(floatingframes, f)

    if os.path.exists(        
        dirname
        + "/handlist_"
        + videoname[:-4]
        + "_"
        + f"{min_hand_detection_confidence*100}{min_hand_presence_confidence*100}{min_tracking_confidence*100}"
        + ".pkl",
    ):
        os.remove(
            dirname
            + "/handlist_"
            + videoname[:-4]
            + "_"
            + f"{min_hand_detection_confidence*100}{min_hand_presence_confidence*100}{min_tracking_confidence*100}"
            + ".pkl",
        )
    with open(
        dirname
        + "/handlist_"
        + videoname[:-4]
        + "_"
        + f"{min_hand_detection_confidence*100}{min_hand_presence_confidence*100}{min_tracking_confidence*100}"
        + ".pkl",
        "wb",
    ) as f:
        pickle.dump(handlist, f)

    print("Data generated and saved")
    print(
        f"faulty frames:{len(faultyframe)}, nohand frames:{len(nohandframelist)}"
    )
    
    # ì²˜ë¦¬ ì™„ë£Œ í›„ ë¶ˆí•„ìš”í•œ íŒŒì¼ë“¤ ì •ë¦¬
    print("Cleaning up temporary files...")
    cleanup_count = 0
    for file in os.scandir(dirname):
        # .pkl íŒŒì¼ê³¼ keyboard.jpgëŠ” ë³´ì¡´, ë‚˜ë¨¸ì§€ëŠ” ì‚­ì œ
        if file.name.endswith('.pkl') or file.name == 'keyboard.jpg':
            continue
        else:
            try:
                os.remove(file.path)
                cleanup_count += 1
            except Exception as e:
                print(f"Warning: Could not remove {file.name}: {e}")
    
    if cleanup_count > 0:
        print(f"Cleaned up {cleanup_count} temporary files")
    
    datatime = timemodule.time()
    print(f"Data generation time: {datatime-start: .5f} sec")




##############################
#datagenerate() ##############
##############################

# ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë£¨í”„
def load_progress_tracker():
    """ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    progress_file = os.path.join(script_dir, "video_processing_progress.json")
    
    if os.path.exists(progress_file):
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        return {}

def save_progress_tracker(progress_data):
    """ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ JSON íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    progress_file = os.path.join(script_dir, "video_processing_progress.json")
    
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress_data, f, indent=2, ensure_ascii=False)

def initialize_progress_tracker(video_files):
    """ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì´ˆê¸° ì²˜ë¦¬ ìƒíƒœë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    progress_data = load_progress_tracker()
    
    # ìƒˆë¡œìš´ íŒŒì¼ë“¤ì„ Falseë¡œ ì´ˆê¸°í™”
    for video_file in video_files:
        if video_file not in progress_data:
            progress_data[video_file] = False
    
    # JSONì— ìˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ì—†ëŠ” íŒŒì¼ë“¤ ì œê±°
    existing_files = set(video_files)
    progress_data = {k: v for k, v in progress_data.items() if k in existing_files}
    
    save_progress_tracker(progress_data)
    return progress_data

def print_progress_summary(progress_data):
    """ì²˜ë¦¬ ì§„í–‰ ìƒí™© ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    total = len(progress_data)
    completed = sum(1 for status in progress_data.values() if status)
    remaining = total - completed
    
    print(f"ğŸ“Š ì²˜ë¦¬ ì§„í–‰ ìƒí™©:")
    print(f"   ì „ì²´: {total}ê°œ")
    print(f"   ì™„ë£Œ: {completed}ê°œ ({completed/total*100:.1f}%)")
    print(f"   ë‚¨ì€: {remaining}ê°œ ({remaining/total*100:.1f}%)")
    
    return total, completed, remaining

def process_all_videos():
    """videocapture í´ë”ì˜ ëª¨ë“  mp4 íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    
    # ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    video_files = []
    if os.path.exists(filepath):
        for file in os.listdir(filepath):
            if file.lower().endswith('.mp4'):
                video_files.append(file)
    
    if not video_files:
        print("âŒ videocapture í´ë”ì— mp4 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íŒŒì¼ëª…ìœ¼ë¡œ ì •ë ¬
    video_files.sort()
    
    print(f"ğŸ¥ ì´ {len(video_files)}ê°œì˜ ë¹„ë””ì˜¤ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“ ë¹„ë””ì˜¤ ê²½ë¡œ: {filepath}")
    
    # ì§„í–‰ ìƒí™© ì¶”ì ê¸° ì´ˆê¸°í™”
    progress_data = initialize_progress_tracker(video_files)
    
    # ì§„í–‰ ìƒí™© ìš”ì•½ ì¶œë ¥
    total, completed, remaining = print_progress_summary(progress_data)
    
    if remaining == 0:
        print("ğŸ‰ ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return
    
    # í‚¤ë³´ë“œ ì •ë³´ íŒŒì¼ í™•ì¸
    keyboard_info_path = os.path.join(script_dir, "keyboardcoordinateinfo.pkl")
    if not os.path.exists(keyboard_info_path):
        print("âŒ keyboardcoordinateinfo.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € í‚¤ë³´ë“œ ì¢Œí‘œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    # ë¯¸ì™„ë£Œ íŒŒì¼ë“¤ë§Œ ì²˜ë¦¬
    unprocessed_files = [f for f, status in progress_data.items() if not status]
    
    print(f"\nğŸ”„ {len(unprocessed_files)}ê°œì˜ ë¯¸ì™„ë£Œ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    processed_count = 0
    failed_files = []
    
    for i, video_file in enumerate(unprocessed_files, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ [{i}/{len(unprocessed_files)}] ì²˜ë¦¬ ì¤‘: {video_file}")
        print(f"   (ì „ì²´ ì§„í–‰ë¥ : {completed + processed_count}/{total})")
        print(f"{'='*60}")
        
        try:
            # í•´ë‹¹í•˜ëŠ” MIDI íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ì„ íƒì‚¬í•­)
            midi_path = os.path.join(script_dir, 'midiconvert', video_file[:-4] + '.mid')
            if os.path.exists(midi_path):
                print(f"âœ… ëŒ€ì‘ë˜ëŠ” MIDI íŒŒì¼ ë°œê²¬: {video_file[:-4]}.mid")
            else:
                print(f"âš ï¸  ëŒ€ì‘ë˜ëŠ” MIDI íŒŒì¼ ì—†ìŒ: {video_file[:-4]}.mid")
            
            # ì‹¤ì œ ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸ (ì´ì¤‘ ì²´í¬)
            output_dir = os.path.join(
                filepath,
                video_file[:-4] + '_' + f"{min_hand_detection_confidence*100}{min_hand_presence_confidence*100}{min_tracking_confidence*100}"
            )
            
            if os.path.exists(output_dir):
                print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì™„ë£Œë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
                progress_data[video_file] = True
                save_progress_tracker(progress_data)
                processed_count += 1
                continue
                
            # ë°ì´í„° ìƒì„± ì‹¤í–‰
            datagenerate(video_file)
            
            # ì„±ê³µ ì‹œ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            progress_data[video_file] = True
            save_progress_tracker(progress_data)
            processed_count += 1
            
            print(f"âœ… [{i}/{len(unprocessed_files)}] ì™„ë£Œ: {video_file}")
            print(f"   ì§„í–‰ ìƒí™©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ [{i}/{len(unprocessed_files)}] ì‹¤íŒ¨: {video_file}")
            print(f"   ì˜¤ë¥˜: {str(e)}")
            failed_files.append(video_file)
            # ì‹¤íŒ¨í•´ë„ ì§„í–‰ ìƒí™©ì€ ì €ì¥ (False ìƒíƒœ ìœ ì§€)
            continue
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì„±ê³µ: {processed_count}ê°œ")
    print(f"   ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì‹¤íŒ¨: {len(failed_files)}ê°œ")
    
    # ìµœì¢… ì§„í–‰ ìƒí™©
    final_total, final_completed, final_remaining = print_progress_summary(progress_data)
    
    if failed_files:
        print(f"\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
        for file in failed_files:
            print(f"   - {file}")
            
    if final_remaining == 0:
        print(f"\nğŸ‰ ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"\nğŸ“ ë‹¤ìŒì— ì²˜ë¦¬í•  íŒŒì¼ë“¤:")
        for video_file, status in progress_data.items():
            if not status:
                print(f"   - {video_file}")
    
    print(f"{'='*60}")

def show_progress_status():
    """í˜„ì¬ ì²˜ë¦¬ ì§„í–‰ ìƒí™©ë§Œ í‘œì‹œí•©ë‹ˆë‹¤."""
    video_files = []
    if os.path.exists(filepath):
        for file in os.listdir(filepath):
            if file.lower().endswith('.mp4'):
                video_files.append(file)
    
    if not video_files:
        print("âŒ videocapture í´ë”ì— mp4 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    video_files.sort()
    progress_data = initialize_progress_tracker(video_files)
    
    print(f"ğŸ“Š ë¹„ë””ì˜¤ ì²˜ë¦¬ ìƒíƒœ í˜„í™©:")
    print(f"{'='*60}")
    
    total, completed, remaining = print_progress_summary(progress_data)
    
    print(f"\nâœ… ì™„ë£Œëœ íŒŒì¼ë“¤:")
    completed_files = [f for f, status in progress_data.items() if status]
    for file in completed_files:
        print(f"   - {file}")
    
    print(f"\nâ³ ëŒ€ê¸°ì¤‘ì¸ íŒŒì¼ë“¤:")
    pending_files = [f for f, status in progress_data.items() if not status]
    for file in pending_files:
        print(f"   - {file}")
    
    print(f"{'='*60}")

if __name__ == "__main__":
    print("ğŸš€ PianoVAM ì† ì¸ì‹ ë°ì´í„° ìƒì„± ë„êµ¬")
    print(f"ğŸ“‚ ì‘ì—… ë””ë ‰í† ë¦¬: {script_dir}")
    
    # ì‚¬ìš©ì ì˜µì…˜
    print("\nì„ íƒí•˜ì„¸ìš”:")
    print("1. ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬")
    print("2. í˜„ì¬ ì§„í–‰ ìƒí™©ë§Œ í™•ì¸")
    
    try:
        choice = input("ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1 ë˜ëŠ” 2): ").strip()
        
        if choice == "1":
            # ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰
            process_all_videos()
        elif choice == "2":
            # ì§„í–‰ ìƒí™©ë§Œ í‘œì‹œ
            show_progress_status()
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¾ ì§„í–‰ ìƒí™©ì€ JSON íŒŒì¼ì— ì €ì¥ë˜ì–´ ìˆì–´ ë‚˜ì¤‘ì— ì´ì–´ì„œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")



def handdetokenizer(originaltokenlist, tokenhandinfo):
    noinfocounter = 0
    outputtoken = []
    for i in range(len(originaltokenlist)):
        if tokenhandinfo[i][-2] == "Right":
            for j in range(len(originaltokenlist[i])):
                if "Program" in originaltokenlist[i][j]:
                    originaltokenlist[i][j] = "Program_0"
        elif tokenhandinfo[i][-2] == "Left":
            for j in range(len(originaltokenlist[i])):
                if "Program" in originaltokenlist[i][j]:
                    originaltokenlist[i][j] = "Program_1"
        elif tokenhandinfo[i][-2] == "noinfo":
            for j in range(len(originaltokenlist[i])):
                if "Program" in originaltokenlist[i][j]:
                    originaltokenlist[i][j] = "Program_2"
                    noinfocounter += 1
    for token in originaltokenlist:
        for attribute in token:
            outputtoken.append(attribute)
    print(f"noinfocount: {noinfocounter}")
    return outputtoken
