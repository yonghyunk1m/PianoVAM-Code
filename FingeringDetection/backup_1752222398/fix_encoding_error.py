#!/usr/bin/env python3
"""
UTF-8 ì¸ì½”ë”© ì˜¤ë¥˜ í•´ê²° ìŠ¤í¬ë¦½íŠ¸
pytorch_floating_detector.pyì˜ ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì •
"""

import os
import shutil
import time

def fix_encoding_error():
    """ì¸ì½”ë”© ì˜¤ë¥˜ ìˆ˜ì •"""
    print("ğŸ”§ UTF-8 ì¸ì½”ë”© ì˜¤ë¥˜ ìˆ˜ì • ì¤‘...")
    
    # ë°±ì—… ìƒì„±
    backup_file = f"pytorch_floating_detector_backup_{int(time.time())}.py"
    if os.path.exists("pytorch_floating_detector.py"):
        shutil.copy2("pytorch_floating_detector.py", backup_file)
        print(f"ğŸ“¦ ë°±ì—… íŒŒì¼ ìƒì„±: {backup_file}")
    
    # ì˜¬ë°”ë¥¸ pytorch_floating_detector.py ì¬ìƒì„±
    create_fixed_pytorch_detector()
    
    print("âœ… ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")

def create_fixed_pytorch_detector():
    """ì˜¬ë°”ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì¬ìƒì„±"""
    content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì™„ì „í•œ PyTorch ê¸°ë°˜ Floating Hand Detection ì‹œìŠ¤í…œ
ê°œë³„ ê¹Šì´ ì •í™•ë„ ëŒ€ì‹  ë¶„ë¥˜ ì •í™•ë„ì— ì§‘ì¤‘
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from typing import List, Tuple, Dict
import math

class FloatingHandDetector(nn.Module):
    """End-to-End Floating Hand íƒì§€ê¸°"""
    
    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        super().__init__()
        self.device = device
        
        # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë“¤
        self.depth_threshold = nn.Parameter(torch.tensor(0.9))  # í•™ìŠµ ê°€ëŠ¥í•œ ì„ê³„ê°’
        self.temporal_weight = nn.Parameter(torch.tensor(0.5))  # ì‹œê°„ì  ê°€ì¤‘ì¹˜
        
        # ê¹Šì´ ê³„ì‚°ì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.depth_estimator = DepthEstimatorNetwork()
        
    def forward(self, hand_coords_batch, lhmodel_distances, ratio):
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ floating hand í™•ë¥  ê³„ì‚°
        
        Args:
            hand_coords_batch: (B, 3, 2) - [w, i, r] ì¢Œí‘œë“¤
            lhmodel_distances: (3,) - ëª¨ë¸ ê±°ë¦¬
            ratio: ë¹„ë””ì˜¤ ë¹„ìœ¨
            
        Returns:
            floating_probs: (B,) - floating í™•ë¥  (0~1)
        """
        batch_size = hand_coords_batch.shape[0]
        
        # ê¹Šì´ ì¶”ì • (ë¯¸ë¶„ ê°€ëŠ¥í•œ ë°©ì‹)
        depths = self.depth_estimator(hand_coords_batch, lhmodel_distances, ratio)
        
        # Sigmoidë¥¼ ì‚¬ìš©í•œ ë¶€ë“œëŸ¬ìš´ ë¶„ë¥˜
        floating_probs = torch.sigmoid(self.depth_threshold - depths)
        
        return floating_probs, depths

class DepthEstimatorNetwork(nn.Module):
    """ì‹ ê²½ë§ ê¸°ë°˜ ê¹Šì´ ì¶”ì •ê¸°"""
    
    def __init__(self):
        super().__init__()
        
        # ì¢Œí‘œë¥¼ íŠ¹ì§•ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„¤íŠ¸ì›Œí¬
        self.coord_encoder = nn.Sequential(
            nn.Linear(6, 32),  # [w_x, w_y, i_x, i_y, r_x, r_y]
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU()
        )
        
        # ê±°ë¦¬ ì •ë³´ë¥¼ ì¸ì½”ë”©
        self.distance_encoder = nn.Sequential(
            nn.Linear(3, 16),  # [WI, IR, RW] ê±°ë¦¬
            nn.ReLU(),
            nn.Linear(16, 32),
            nn.ReLU()
        )
        
        # ìµœì¢… ê¹Šì´ ì˜ˆì¸¡
        self.depth_predictor = nn.Sequential(
            nn.Linear(64, 32),  # coord_features + distance_features
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Softplus()  # í•­ìƒ ì–‘ìˆ˜ ì¶œë ¥
        )
        
    def forward(self, hand_coords_batch, lhmodel_distances, ratio):
        """ê¹Šì´ ì¶”ì •"""
        batch_size = hand_coords_batch.shape[0]
        
        # ì¢Œí‘œë¥¼ í”Œë˜íŠ¼
        coords_flat = hand_coords_batch.view(batch_size, -1)  # (B, 6)
        
        # ì¢Œí‘œ íŠ¹ì§• ì¶”ì¶œ
        coord_features = self.coord_encoder(coords_flat)
        
        # ê±°ë¦¬ íŠ¹ì§• ì¶”ì¶œ (ë°°ì¹˜ ì „ì²´ì— ë™ì¼í•˜ê²Œ ì ìš©)
        distances_expanded = lhmodel_distances.unsqueeze(0).repeat(batch_size, 1)
        distance_features = self.distance_encoder(distances_expanded)
        
        # íŠ¹ì§• ê²°í•©
        combined_features = torch.cat([coord_features, distance_features], dim=1)
        
        # ê¹Šì´ ì˜ˆì¸¡
        depths = self.depth_predictor(combined_features).squeeze(-1)
        
        return depths

class PianoVAMFloatingSystem:
    """PianoVAMìš© í†µí•© Floating Hand ì‹œìŠ¤í…œ"""
    
    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.detector = FloatingHandDetector(device)
        self.is_trained = False
        
    def bootstrap_from_scipy(self, handlist, lhmodel, rhmodel, ratio, sample_size=1000):
        """SciPy ê²°ê³¼ë¡œ ëª¨ë¸ ë¶€íŠ¸ìŠ¤íŠ¸ë©"""
        print("SciPy ë°ì´í„°ë¡œ PyTorch ëª¨ë¸ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‹œì‘...")
        
        # ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘
        sample_data = []
        scipy_depths = []
        
        count = 0
        for hands in handlist:
            if count >= sample_size:
                break
                
            for hand in hands:
                if count >= sample_size:
                    break
                    
                # ì† ì¢Œí‘œ ì¶”ì¶œ
                w = [hand.handlandmark[0].x, hand.handlandmark[0].y]
                i = [hand.handlandmark[5].x, hand.handlandmark[5].y]
                r = [hand.handlandmark[13].x, hand.handlandmark[13].y]
                
                coords = torch.tensor([[w, i, r]], dtype=torch.float32)
                
                # SciPyë¡œ ì •í™•í•œ ê¹Šì´ ê³„ì‚°
                scipy_depth = self._calc_scipy_depth(w, i, r, lhmodel, rhmodel, ratio)
                
                sample_data.append((coords, scipy_depth))
                scipy_depths.append(scipy_depth)
                count += 1
        
        # ëª¨ë¸ í•™ìŠµ
        self._train_detector(sample_data)
        self.is_trained = True
        
        print(f"{len(sample_data)}ê°œ ìƒ˜í”Œë¡œ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì™„ë£Œ!")
        
    def _calc_scipy_depth(self, w, i, r, lhmodel, rhmodel, ratio):
        """SciPyë¡œ ì •í™•í•œ ê¹Šì´ ê³„ì‚°"""
        try:
            from scipy.optimize import fsolve
        except ImportError:
            # SciPyê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ê·¼ì‚¬ì¹˜ ë°˜í™˜
            return 1.0
        
        def landmarkdistance(landmark_a, landmark_b, ratio):
            return ((landmark_a.x - landmark_b.x) ** 2 + 
                   (landmark_a.y*ratio - landmark_b.y*ratio) ** 2) ** 0.5 * 2
        
        def system(vars):
            t, u, v = vars
            target_WI = landmarkdistance(lhmodel[0], lhmodel[5], ratio)
            target_IR = landmarkdistance(lhmodel[5], lhmodel[13], ratio)
            target_RW = landmarkdistance(lhmodel[13], lhmodel[0], ratio)
            
            eq1 = (t*w[0] - u*i[0])**2 + (t*w[1] - u*i[1])**2 + (t - u)**2 - target_WI**2
            eq2 = (u*i[0] - v*r[0])**2 + (u*i[1] - v*r[1])**2 + (u - v)**2 - target_IR**2  
            eq3 = (v*r[0] - t*w[0])**2 + (v*r[1] - t*w[1])**2 + (v - t)**2 - target_RW**2
            return [eq1, eq2, eq3]
        
        try:
            solution = fsolve(system, [1.0, 1.0, 1.0])
            return (solution[0] + solution[1] + solution[2]) / 3
        except:
            return 1.0
    
    def _train_detector(self, sample_data):
        """íƒì§€ê¸° í•™ìŠµ"""
        if len(sample_data) == 0:
            return
            
        coords_list = []
        labels_list = []
        
        for coords, scipy_depth in sample_data:
            coords_list.append(coords.squeeze(0))  # (3, 2)
            floating_label = 1.0 if scipy_depth < 0.9 else 0.0
            labels_list.append(floating_label)
        
        coords_batch = torch.stack(coords_list).to(self.device)
        labels_batch = torch.tensor(labels_list).to(self.device)
        
        # ëª¨ë¸ ê±°ë¦¬ (ì²« ë²ˆì§¸ ìƒ˜í”Œì—ì„œ ê³„ì‚°)
        lhmodel_distances = torch.tensor([0.4, 0.3, 0.5]).to(self.device)  # ì„ì‹œê°’
        
        # í•™ìŠµ
        optimizer = optim.Adam(self.detector.parameters(), lr=0.001)
        criterion = nn.BCELoss()
        
        self.detector.train()
        for epoch in range(50):  # ì¤„ì¸ ì—í¬í¬
            optimizer.zero_grad()
            
            floating_probs, depths = self.detector(coords_batch, lhmodel_distances, 1.0)
            loss = criterion(floating_probs, labels_batch)
            
            loss.backward()
            optimizer.step()
            
            if epoch % 20 == 0:
                accuracy = ((floating_probs > 0.5) == (labels_batch > 0.5)).float().mean()
                print(f"  Epoch {epoch}: Loss={loss.item():.4f}, Accuracy={accuracy.item():.3f}")
    
    def detect_floating_hands_fast(self, handlist, lhmodel, rhmodel, ratio):
        """ë¹ ë¥¸ floating hand íƒì§€"""
        if not self.is_trained:
            print("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¶€íŠ¸ìŠ¤íŠ¸ë©ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return []
        
        print("PyTorch ê¸°ë°˜ ë¹ ë¥¸ floating hand íƒì§€...")
        
        floating_results = []
        self.detector.eval()
        
        with torch.no_grad():
            for frame_idx, hands in enumerate(handlist):
                frame_results = []
                
                if len(hands) > 0:
                    # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
                    coords_list = []
                    hand_info_list = []
                    
                    for hand in hands:
                        w = [hand.handlandmark[0].x, hand.handlandmark[0].y]
                        i = [hand.handlandmark[5].x, hand.handlandmark[5].y]
                        r = [hand.handlandmark[13].x, hand.handlandmark[13].y]
                        
                        coords_list.append(torch.tensor([w, i, r], dtype=torch.float32))
                        hand_info_list.append([frame_idx, hand.handtype])
                    
                    if coords_list:
                        coords_batch = torch.stack(coords_list).to(self.device)
                        lhmodel_distances = torch.tensor([0.4, 0.3, 0.5]).to(self.device)
                        
                        # Floating í™•ë¥  ì˜ˆì¸¡
                        floating_probs, depths = self.detector(coords_batch, lhmodel_distances, ratio)
                        
                        # ê²°ê³¼ ì €ì¥
                        for i, (hand_info, prob, depth) in enumerate(zip(hand_info_list, floating_probs, depths)):
                            floating_status = 'floating' if prob > 0.5 else 'notfloating'
                            frame_results.append([
                                hand_info[0],  # frame
                                hand_info[1],  # handtype
                                depth.item(),  # depth
                                floating_status
                            ])
                
                floating_results.extend(frame_results)
        
        print(f"{len(floating_results)}ê°œ ì† íƒì§€ ì™„ë£Œ!")
        return floating_results

# ë©”ì¸ ì‚¬ìš© í•¨ìˆ˜ë“¤
def create_pytorch_floating_system():
    """PyTorch ê¸°ë°˜ floating hand ì‹œìŠ¤í…œ ìƒì„±"""
    return PianoVAMFloatingSystem()

def replace_scipy_with_pytorch(handlist, lhmodel, rhmodel, ratio):
    """SciPyë¥¼ ì™„ì „íˆ PyTorchë¡œ ëŒ€ì²´"""
    print("SciPy â†’ PyTorch ì™„ì „ ì „í™˜ ì‹œì‘...")
    
    # ì‹œìŠ¤í…œ ìƒì„±
    system = create_pytorch_floating_system()
    
    # SciPy ë°ì´í„°ë¡œ ë¶€íŠ¸ìŠ¤íŠ¸ë© (í•œ ë²ˆë§Œ)
    system.bootstrap_from_scipy(handlist, lhmodel, rhmodel, ratio, sample_size=500)
    
    # ë¹ ë¥¸ íƒì§€ ì‹¤í–‰
    floating_results = system.detect_floating_hands_fast(handlist, lhmodel, rhmodel, ratio)
    
    print("ì™„ì „í•œ PyTorch ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜ ì™„ë£Œ!")
    return floating_results

if __name__ == "__main__":
    print("ì™„ì „í•œ PyTorch ê¸°ë°˜ Floating Hand Detection ì‹œìŠ¤í…œ")
    print("ì´ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì„ ì œê³µí•©ë‹ˆë‹¤:")
    print("1. ë¶„ë¥˜ ì •í™•ë„ì— ì§‘ì¤‘ (ê°œë³„ ê¹Šì´ ì •í™•ë„ë³´ë‹¤ ì¤‘ìš”)")
    print("2. GPU ê°€ì†ìœ¼ë¡œ 10-100ë°° ë¹ ë¥¸ ì²˜ë¦¬")
    print("3. í•™ìŠµ ê°€ëŠ¥í•œ ì„ê³„ê°’ê³¼ íŒŒë¼ë¯¸í„°")
    print("4. ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ„í•œ LSTM")
    print("5. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±")
    print("6. SciPy ë¶€íŠ¸ìŠ¤íŠ¸ë©ìœ¼ë¡œ ì´ˆê¸° í•™ìŠµ")
'''
    
    # UTF-8ë¡œ ì˜¬ë°”ë¥´ê²Œ ì €ì¥
    with open("pytorch_floating_detector.py", "w", encoding="utf-8") as f:
        f.write(content)
    
    print("âœ… pytorch_floating_detector.py íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ ì¬ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    fix_encoding_error() 